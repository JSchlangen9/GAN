{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTSA 5511: GAN Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "For this project, I will be competiting in the \"I'm Something of a Painter Myself\" competition from Kaggle. The objective will be to create a deep learning model that can be trained on images of paintings and then create new images of paintings on its own. The trained model will take ordinary pictures and turn them into \"Monet\" style paintings. My initial plan is to construct a GAN model using layers from the Keras library, and make adjustments as time permits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries & Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monet Images Data Set\n",
    "\n",
    "Here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files.\n",
      "Found 7038 files.\n"
     ]
    }
   ],
   "source": [
    "#Loading in Processed Images\n",
    "def load_images(dir):\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        dir,\n",
    "        image_size=(256, 256),\n",
    "        batch_size=1,\n",
    "        label_mode=None\n",
    "    )\n",
    "    return dataset.map(lambda x: (x - 128) / 128).repeat()\n",
    "\n",
    "monet_dataset = load_images('/Users/jschlangen/Desktop/gan-getting-started/monet_jpg')\n",
    "photo_dataset = load_images('/Users/jschlangen/Desktop/gan-getting-started/photo_jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD EDA HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "Here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct Image Generator\n",
    "def build_generator():\n",
    "    inputs = layers.Input(shape=(256, 256, 3))\n",
    "    x = layers.Conv2D(64, kernel_size=7, padding='same', activation='relu')(inputs)\n",
    "    x = layers.Conv2D(128, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "    outputs = layers.Conv2D(3, kernel_size=7, padding='same', activation='tanh')(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "my_generator = build_generator()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contruct and Train GAN Model\n",
    "@tf.function\n",
    "def train(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        yp = my_generator(x)\n",
    "        loss = tf.reduce_mean(tf.square(yp - y))\n",
    "\n",
    "    grads = tape.gradient(loss, my_generator.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(grads, my_generator.trainable_variables))\n",
    "\n",
    "epochs = 5\n",
    "steps = 350\n",
    "for epoch in range(epochs):\n",
    "    for step in range(steps):\n",
    "        x = next(iter(photo_dataset))\n",
    "        y = next(iter(monet_dataset))\n",
    "        train(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results & Analysis\n",
    "\n",
    "Here...\n",
    "\n",
    "Add Submission image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Images\n",
    "output_loc = 'generated_images'\n",
    "os.makedirs(output_loc, exist_ok=True)\n",
    "\n",
    "count = 0\n",
    "max_images = 10000\n",
    "\n",
    "for x in photo_dataset:\n",
    "    while count < max_images:\n",
    "        image = my_generator(x)[0]\n",
    "        image = ((image.numpy() + 1) * 255 / 2).astype(int)\n",
    "        \n",
    "        filename = os.path.join(output_loc, 'generated_' + str(count) + '.jpg')\n",
    "        tf.keras.preprocessing.image.save_img(filename, image)\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create .zip file for Kaggle Submission\n",
    "with zipfile.ZipFile('images.zip', 'w') as zipf:\n",
    "    for root, _, files in os.walk(output_loc):\n",
    "        for file in files:\n",
    "            zipf.write(os.path.join(root, file), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
